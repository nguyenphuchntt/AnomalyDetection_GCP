# cmd
# cd LoadTest_GCP
# venv\Scripts\activate.bat
# python latency_monitor.py

import time
import json
import threading
import numpy as np
from google.cloud import pubsub_v1

# --- Cáº¤U HÃŒNH ---
PROJECT_ID = "int3319-477808"
# Topic Ä‘áº§u ra
SUBSCRIPTION_ID = "latency-monitor-sub" 

# Biáº¿n lÆ°u trá»¯ toÃ n bá»™ dá»¯ liá»‡u (Cá»™ng dá»“n)
all_latencies = []
start_time = None

def callback(message):
    global all_latencies, start_time
    
    if start_time is None:
        start_time = time.time()

    try:
        data_str = message.data.decode("utf-8")
        data_json = json.loads(data_str)
        trans_id = data_json.get("id")
        
        # Lá»c tin nháº¯n cÃ³ prefix LOCUST-
        if trans_id and "LOCUST-" in trans_id: 
            parts = trans_id.split("-")
            sent_time_ms = int(parts[1])
            receive_time_ms = int(time.time() * 1000)
            
            # TÃ­nh Ä‘á»™ trá»…
            latency_ms = receive_time_ms - sent_time_ms
            all_latencies.append(latency_ms)
        
        message.ack()
    except Exception:
        message.ack()

def print_stats_loop():
    """VÃ²ng láº·p in bÃ¡o cÃ¡o má»—i 5 giÃ¢y"""
    last_count = 0
    
    print(f"ğŸš€ Äang láº¯ng nghe... (Sá»‘ liá»‡u Full Option)")
    print(f"â³ Chá» dá»¯ liá»‡u Ä‘á»• vá»...")
    
    while True:
        time.sleep(5)
        
        current_count = len(all_latencies)
        
        # Náº¿u chÆ°a cÃ³ dá»¯ liá»‡u má»›i thÃ¬ bá» qua
        if current_count == 0:
            continue
            
        # --- TÃNH TOÃN Sá» LIá»†U ---
        arr = np.array(all_latencies)
        
        # 1. Throughput (ThÃ´ng lÆ°á»£ng)
        # Tá»‘c Ä‘á»™ tá»©c thá»i (trong 5s qua)
        msg_in_last_window = current_count - last_count
        current_rps = msg_in_last_window / 5.0
        last_count = current_count
        
        # Tá»‘c Ä‘á»™ trung bÃ¬nh toÃ n trÃ¬nh (tá»« lÃºc báº¯t Ä‘áº§u)
        elapsed_time = time.time() - start_time
        overall_rps = current_count / elapsed_time if elapsed_time > 0 else 0

        # 2. Latency (Äá»™ trá»…)
        avg = np.mean(arr)
        p50 = np.median(arr)
        p90 = np.percentile(arr, 90)
        p95 = np.percentile(arr, 95)
        p99 = np.percentile(arr, 99)      # <--- Cá»§a báº¡n Ä‘Ã¢y
        p999 = np.percentile(arr, 99.9)   # <--- DÃ nh cho nhá»¯ng ca siÃªu cháº­m
        std_dev = np.std(arr)             # <--- Äá»™ á»•n Ä‘á»‹nh (cÃ ng nhá» cÃ ng tá»‘t)
        min_lat = np.min(arr)
        max_lat = np.max(arr)

        print("\n" + "="*60)
        print(f"â±ï¸  BÃO CÃO Cáº¬P NHáº¬T (Tá»•ng máº«u: {current_count})")
        print("-" * 60)
        print(f"ğŸš€ THÃ”NG LÆ¯á»¢NG (THROUGHPUT):")
        print(f"   âš¡ Tá»‘c Ä‘á»™ hiá»‡n táº¡i:   {current_rps:.1f} req/s (Äang xá»­ lÃ½)")
        print(f"   ğŸŒ Tá»‘c Ä‘á»™ trung bÃ¬nh: {overall_rps:.1f} req/s (ToÃ n trÃ¬nh)")
        print("-" * 60)
        print(f"ğŸ“¡ Äá»˜ TRá»„ (LATENCY) - ms:")
        print(f"   âœ… Trung bÃ¬nh (Avg):  {avg:.2f}")
        print(f"   âœ… P50 (Trung vá»‹):    {p50:.2f}  <-- Quan trá»ng nháº¥t")
        print(f"   âš ï¸ P90 (90%):         {p90:.2f}")
        print(f"   âš ï¸ P95 (95%):         {p95:.2f}")
        print(f"   ğŸ”¥ P99 (99%):         {p99:.2f}  <-- Chá»‰ sá»‘ cam káº¿t SLA")
        print(f"   â˜ ï¸ P99.9 (99.9%):     {p999:.2f}")
        print(f"   ğŸ“‰ Min / Max:         {min_lat} / {max_lat}")
        print(f"   ã€°ï¸ Äá»™ lá»‡ch chuáº©n:     {std_dev:.2f} (Jitter)")
        print("="*60)

if __name__ == "__main__":
    subscriber = pubsub_v1.SubscriberClient()
    subscription_path = subscriber.subscription_path(PROJECT_ID, SUBSCRIPTION_ID)
    
    stats_thread = threading.Thread(target=print_stats_loop)
    stats_thread.daemon = True
    stats_thread.start()

    streaming_pull_future = subscriber.subscribe(subscription_path, callback=callback)
    
    try:
        streaming_pull_future.result()
    except KeyboardInterrupt:
        print("\nğŸ›‘ ÄÃ£ dá»«ng monitor.")